{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wczytanie bibliotek\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Wczytanie danych produkt-kategoria\n",
    "dane_kategorie = pd.read_csv('C:\\\\Users\\\\mateu\\\\OneDrive\\\\Pulpit\\\\wyg.dane_kategorie.csv')\n",
    "kategorie = dane_kategorie.pivot_table(index='kategoriaid',columns='produktid',values='value')\n",
    "kategorie.head(15)\n",
    "# 2. Wczytanie danych klient-produkt\n",
    "dane_aktywnosc = pd.read_csv('C:\\\\Users\\\\mateu\\\\OneDrive\\\\Pulpit\\\\wyg.dane_aktywnosc.csv')\n",
    "aktywnosc = dane_aktywnosc.pivot_table(index='klientid',columns='produktid',values='zdarzenie')\n",
    "aktywnosc = aktywnosc.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Przygotowanie populacji\n",
    "#docelowy klient - klient z id = 1\n",
    "\n",
    "docKlient = aktywnosc.iloc[[2]]\n",
    "docKlient\n",
    "\n",
    "produkty_obejrzane = docKlient.loc[:, (docKlient != 0).any()]\n",
    "produkty_obejrzane   \n",
    "\n",
    "populacja_aktywnosc = aktywnosc.drop(columns = produkty_obejrzane)\n",
    "populacja_kategorie = kategorie.drop(columns = produkty_obejrzane)\n",
    "\n",
    "n = 16\n",
    "populacja_osobnikow_kategorie = np.split(populacja_kategorie, n, axis=1)\n",
    "populacja_osobnikow_aktywnosc = np.split(populacja_aktywnosc, n, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Obliczanie korelacji produktow\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "jac_sim = 1 - pairwise_distances(populacja_osobnikow_kategorie[0].T, metric = \"hamming\")  # jaccard_similarity_score (1 - hamming)\n",
    "# optionally convert it to a DataFrame\n",
    "jac_sim = pd.DataFrame(jac_sim, index=populacja_osobnikow_kategorie[0].columns,\n",
    "                       columns=populacja_osobnikow_kategorie[0].columns)\n",
    "jac_sim.head(100)\n",
    "\n",
    "jac_sim.sum().sum() # Korelacja(z) - wartosc korelacji produktow osobnika o indeksie 0\n",
    "\n",
    "\n",
    "jac_sim2= (1 - pairwise_distances(populacja_osobnikow_kategorie[1].T, metric = \"hamming\"))/2\n",
    "jac_sim3= 1 - pairwise_distances(populacja_osobnikow_kategorie[2].T, metric = \"hamming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Selekcja metoda kola ruletki\n",
    "\n",
    "# przykladowa populacja: population = [[0,0,1,0,0,0,1],[0,1,0,0,0,0,0]]\n",
    "# po zastosowaniu funkcji przystosowania otrzymujemy 'dictionary' z osobnikiem i \n",
    "#  wartościa funkcji przystosowania przyklad : population_fitness_dictionary = {\"0,0,1,0,0,0,1\": 1.245, \"0,1,0,0,0,0,0\":1.658}\n",
    "\n",
    "\n",
    "\n",
    "def get_probability_list():\n",
    "    fitness = slownik.values()\n",
    "    total_fit = float(sum(fitness))\n",
    "    relative_fitness = [f/total_fit for f in fitness]\n",
    "    probabilities = [sum(relative_fitness[:i+1]) \n",
    "                     for i in range(len(relative_fitness))]\n",
    "    return probabilities\n",
    "\n",
    "def roulette_wheel_pop(population, probabilities, number):\n",
    "    chosen = []\n",
    "    for n in range(number):\n",
    "        r = random.random()\n",
    "        for (i, individual) in enumerate(population):\n",
    "            if r <= probabilities[i]:\n",
    "                chosen.append(list(individual))\n",
    "                break\n",
    "    return chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Krzyzowanie\n",
    "def Crossover(parent1,parent2,point):\n",
    "    p1,p2 = list(parent1),list(parent2) #convert str to list\n",
    "    for i in range(point,len(p1)):\n",
    "        p1[i],p2[i] = p2[i],p1[i]       #swap the genetic information\n",
    "    p1,p2 = ''.join(p1),''.join(p2)     #Convert list to str\n",
    "    return p1,p2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. mutacja\n",
    "def mutate(individual):\n",
    "    next_x = individual[\"x\"] + random.uniform(-0.05, 0.05)\n",
    "    next_y = individual[\"y\"] + random.uniform(-0.05, 0.05)\n",
    "\n",
    "    lower_boundary, upper_boundary = (-4, 4)\n",
    "\n",
    "    # Guarantee we keep inside boundaries\n",
    "    next_x = min(max(next_x, lower_boundary), upper_boundary)\n",
    "    next_y = min(max(next_y, lower_boundary), upper_boundary)\n",
    "\n",
    "    return {\"x\": next_x, \"y\": next_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Podobienśtwo użytkowników\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Obliczenie wartosci predykcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. wygenerowana lista rekomendowanych produktow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
